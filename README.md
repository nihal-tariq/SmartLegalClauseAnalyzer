âš–ï¸ Smart Legal Clause Analyzer

RAG-based Legal AI System

A production-grade Legal AI Assistant that leverages LLMs, Retrieval-Augmented Generation (RAG), and multi-format document processing to:

Analyze legal documents

Classify user intent

Generate legally informed answers

ğŸš€ Built with: LangChain, FastAPI, Groq (LLaMA3-70B), Gemini 2.5 Flash, Celery, HuggingFace, PostgreSQL, and Docker.
Demonstrates scalable architecture, modular design, and advanced LLM integrations.

ğŸ”— Repository: GitLab â€“ Smart Legal Clause Analyzer

âš¡ Quick Start (Docker Setup)
# 1. Clone the Repository
git clone https://gitlab.com/nihaltariq66/Smart_Legal_Clause_Analyzez.git
cd Smart_Legal_Clause_Analyzez

# 2. Create a .env file and add your API keys + DB config
touch .env
# Add GOOGLE_API_KEY, GROQ_API_KEY, CHATLOG_DATABASE, etc.

# 3. Build and run containers
docker-compose up --build

# 4. (Subsequent Runs)
docker-compose up


ğŸ“¡ Services:

ğŸ§  FastAPI â†’ http://localhost:8007

ğŸ˜ PostgreSQL â†’ localhost:5433

â™»ï¸ Redis â†’ localhost:6380

ğŸ“œ Project Summary

This system delivers a multi-stage intelligent legal assistant pipeline:

Document Uploads â†’ PDF, Word, CSV

Parsing & Chunking â†’ via LangChain loaders

Embeddings & Storage â†’ HuggingFace Mini LLM + ChromaDB (per-user + central legal DB)

Query Classification â†’

Legal vs Non-Legal â†’ Gemini 2.5 Flash

Intent Classification â†’ BART MNLI (Definition, Clause Retrieval, Comparative Analysis)

Context Retrieval â†’ Multi-query search from User DB + Main DB

Answer Generation â†’ Gemini 2.5 Flash

Logging â†’ Chat history stored in PostgreSQL, exportable as JSON

ğŸ§  Architecture Overview
flowchart TD
    A[User Uploads PDF/Word/CSV] --> B[LangChain Document Loaders]
    B --> C[Chunk & Embed via HuggingFace Mini LLM]
    C --> D[User-specific ChromaDB Collection]
    C --> E[Main ChromaDB (Legal CSVs)]

    F[User Query] --> G[Gemini 2.5 Flash: Legal/Non-Legal]
    G -->|Yes| H[Intent Classifier: BART MNLI]
    H --> I[Context Retrieval: User + Main DB]
    I --> J[Gemini 2.5 Flash Generates Response]
    J --> K[Response Stored in PostgreSQL]
    K --> M[Retrieve via /chat_log & /download-chatlog]

    G -->|No| N[Return "Please enter a legal query"]

ğŸ”¬ Key Components
ğŸ“„ Document Ingestion

Formats: PDF, Word, CSV

Loaders: PyMuPDFLoader, Docx2txtLoader, CSVLoader

Stored in user-specific ChromaDB collections, linked via user_id

ğŸ§  LLM & Retrieval Stack

Retriever â†’ LLaMA3-70B (Groq) + ContextualCompressionRetriever + MultiQueryRetriever

Legal/Non-Legal Classifier â†’ Gemini 2.5 Flash

Intent Classifier â†’ BART-MNLI (zero-shot)

Responder â†’ Gemini 2.5 Flash

Embedder â†’ HuggingFace Mini-LLM

âš™ï¸ Background Processing

Celery workers (task queue)

Redis backend

Handles asynchronous embedding & storage

ğŸ—ƒï¸ Data Storage

ChromaDB â†’ Persistent vector DB (per-user + central legal knowledgebase)

PostgreSQL â†’ File metadata + chat history (linked to user_id)

ğŸ“¦ Deployment-Ready (Dockerized)

âœ… Containers:

FastAPI

Celery Worker

PostgreSQL

Redis

âœ… Features:

.env driven config

Persistent volumes (DB + ChromaDB)

Scalable, restart-safe setup

ğŸ”® Future Roadmap

ğŸ” OAuth2-based authentication (User roles: Lawyer, Client, Admin)

ğŸ’¬ Frontend with live chat + doc upload

ğŸ“‘ Advanced legal summarization & comparison tools

ğŸ“Š Analytics dashboard for case trends & query insights